const { Telegraf } = require('telegraf');
const { Configuration, OpenAIApi } = require("openai");
const axios = require('axios');
const dontev = require('dotenv').config();
const bot = new Telegraf(process.env.BOOT_TOKEN);


//Set bot commands
bot.telegram.setMyCommands([
    {command: 'start', description:'–ù–∞—á–∞–ª—å–Ω–æ–µ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ'},
    {command: 'english', description:'–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞'},
    {command: 'jscode', description:'–ù–∞–ø–∏—Å–∞—Ç—å –∫–æ–¥ –Ω–∞ JS'},
    {command: 'text', description:'–ù–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç'},
    {command: 'faq', description:'–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã'},
    {command: 'product', description:'–ü—Ä–∏–¥—É–º–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ'},
    {command: 'chat', description:'–ß–∞—Ç —Å –ò–ò'},
    {command: 'interview', description:'–°–æ–∑–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é'},
])

//Start command
bot.start(async (ctx) => {
    await ctx.reply('üëã')
    await ctx.reply(`–ü—Ä–∏–≤–µ—Ç, ${ctx.from.first_name}`)
    await ctx.reply('–Ø –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É—é —Å OpenAI API –∏ –º–æ–≥—É –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ç–µ–º–∞–º')
    await ctx.reply('–î–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ 2021 –≥–æ–¥—É, –ø–æ—ç—Ç–æ–º—É –ò–ò –º–æ–∂–µ—Ç –Ω–µ –∑–Ω–∞—Ç—å –æ —Ç–µ–∫—É—â–∏—Ö —Å–æ–±—ã—Ç–∏—è—Ö.‚ö†Ô∏è')
    await ctx.reply('–î–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –±–æ—Ç–æ–º –≤—ã–±–µ—Ä–µ—Ç–µ –º–æ–¥–µ–ª—å –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –º–µ–Ω—é‚ú®')
})

function getOpenai(model, prompt, temperature, max_tokens, top_p, frequency_penalty, presence_penalty) {
    bot.on('message', async (ctx) =>{
        const messageText = ctx.message.text;
        try {
            const configuration = new Configuration({apiKey: process.env.API_KEY,});
            const openai = new OpenAIApi(configuration);          
            const response = await openai.createCompletion({
                model,
                prompt: prompt + messageText,
                temperature,
                max_tokens,
                top_p,
                frequency_penalty,
                presence_penalty,
            });
            await ctx.reply(response.data.choices[0].text);

        }catch (error) {
            await ctx.reply('–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫üò±')
            await ctx.reply(`–ö–æ–¥ –æ—à–∏–±–∫–∏ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞: ${error.response.status}`)
        }
    })
  }

//English grammar command
bot.command('english', async (ctx) => {
    await ctx.reply('–í–≤–µ–¥–∏—Ç–µ –≤–∞—à —Ç–µ–∫—Å—Ç! \n–ë–æ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ—Ç –≤—Å–µ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —è–∑—ã–∫', getOpenai("text-davinci-003", 'Correct this to standard English:', 0.1, 500, 1.0, 0.5, 0.0))
})

//Create jscode command
bot.command('jscode', async (ctx) => {
    await ctx.reply('–£–∫–∞–∂–∏—Ç–µ —á—Ç–æ –∏–º–µ–Ω–Ω–æ –¥–æ–ª–∂–µ–Ω –¥–µ–ª–∞—Ç—å –≤–∞—à –∫–æ–¥? –ö–∞–∫–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?', getOpenai("text-davinci-002", 'Write this code using ES6 JavaScript:', 0, 1000, 1.0, 0.5, 0.0))
})

//Create text command
bot.command('text', async (ctx) => {
    await ctx.reply('–ß—Ç–æ –∏–º–µ–Ω–Ω–æ –Ω—É–∂–Ω–æ –Ω–∞–ø–∏—Å–∞—Ç—å?')
    await ctx.reply('–ü—Ä–∏–º–µ—Ä: \n–ù–∞–ø–∏—à–∏ —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É "–ü—Ä–æ–±–ª–µ–º—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –º–∏—Ä–∞"', getOpenai("text-davinci-003", '–°–æ–∑–¥–∞–π –≥—Ä–∞–º–æ—Ç–Ω—ã–π –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π:', 0.55, 800, 1.0, 0.5, 0.0))
})

//Create faq command
bot.command('faq', async (ctx) => {
    await ctx.reply('–û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∏–º–µ—é—â–∏—Ö—Å—è –∑–Ω–∞–Ω–∏—è—Ö', getOpenai("text-davinci-003", '–î–∞–π —Ç–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å:', 0, 800, 1, 0.0, 0.0))
})

//Create product command
bot.command('product', async (ctx) => {
    await ctx.reply('–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –¥–ª—è –±—Ä–µ–Ω–¥–∞, –∏–º—è –∂–∏–≤–æ—Ç–Ω–æ–≥–æ...', getOpenai("text-davinci-003", '–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 6 –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π:', 0.8, 700, 1.0, 0.0, 0.0))
})

//Create chat command
bot.command('chat', async (ctx) => {
    await ctx.reply('–ù–∞—á–Ω–∏ —Å–≤–æ–π —á–∞—Ç —Å –ò–ò')
    await ctx.reply('–ë–æ—Ç –Ω–µ —É–º–µ–µ—Ç –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –ø—Ä–æ—à–ª–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –æ—Ç–≤–µ—Ç –≤—ã –ø–æ–ª—É—á–∞–µ—Ç–µ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞!', getOpenai("text-davinci-003", '', 0.7, 500, 1, 0.5, 0.8))
})

//Create interview command
bot.command('interview', async (ctx) => {
    await ctx.reply('–ü—Ä–∏–º–µ—Ä: \n–°–æ—Å—Ç–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ –∏–∑ 8 –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é —Å –∞–≤—Ç–æ—Ä–æ–º –Ω–∞—É—á–Ω–æ–π —Ñ–∞–Ω—Ç–∞—Å—Ç–∏–∫–∏:', getOpenai("text-davinci-003", '', 0.5, 700, 1.0, 0.0, 0.0))
})

bot.launch()